{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26516d7-6d92-470b-8800-934cef4d4f29",
   "metadata": {},
   "source": [
    "# Scraping Toots about IKEA from Mastodon Social \n",
    "\n",
    "This notebook is a bit more advanced. It will only come with little explanations regarding the code. If you need more guidance, please refer to the notebook Mastodon_Migros_Prototype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7c8981-4fe4-44f1-a5ea-01747572b5f4",
   "metadata": {},
   "source": [
    "## Load libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5668a5f8-60a7-49fa-a34b-866f8485fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fce9be-0d6f-4ebe-8b65-d26ac0a5906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a62b36-1fba-469f-9d92-3c789260712c",
   "metadata": {},
   "source": [
    "## Preparation - Defining hashtag and URL for requests, set timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdaab0ff-dd36-42fc-a44b-a952dc06420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_hashtag():\n",
    "\n",
    "    hashtag = input(\"Enter the hashtag which you would like to search: \")\n",
    "    return hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ec8796-0ebb-4712-a9ff-7aea0dae4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_mastodon_instance():\n",
    "\n",
    "    instance = input(\"Enter the Mastodon instance you would like to scrape. \" \n",
    "    \"Good starting points are for example mastodon.social, mastodon.world. \"\n",
    "    \"Make sure, you enter the entire name of the instance, e.g. mastodon.world. \"\n",
    "    \"Instance of choice: \")\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06eaebf1-e4fe-4db6-814e-924bf7c5af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url():\n",
    "\n",
    "    user_hashtag = ask_for_hashtag()\n",
    "    cleaned_hashtag = user_hashtag.lower()\n",
    "\n",
    "    user_instance = ask_for_mastodon_instance()\n",
    "    cleaned_instance = user_instance.lower()\n",
    "\n",
    "    url = f'https://{cleaned_instance}/api/v1/timelines/tag/{cleaned_hashtag}'\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9663c4-0e49-4f3a-9ff2-db7f13775601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_starting_date():\n",
    "\n",
    "    user_starting_date = input(\"Please enter the date you would like to start scraping. \"\n",
    "                          \"Tip: Depending on the hashtag, start with a short time period. \"\n",
    "                          \"Use the YYYY-MM-DD notation: \")\n",
    "\n",
    "    return user_starting_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a10bad-4ad9-49b7-b568-3a238170831b",
   "metadata": {},
   "source": [
    "## Scraping the toots\n",
    "\n",
    "The following code now actually fetches recent posts with a specific hashtag from Mastodon and stores them in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d194dd01-a899-4df5-9cab-49f646485395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_toots():\n",
    "    \n",
    "    params = {'limit': 40} #one can only fetch 40 posts at once\n",
    "    \n",
    "    URL = build_url()\n",
    "    print(URL)\n",
    "    \n",
    "    date = ask_for_starting_date()\n",
    "    since = pd.Timestamp(f'{date} 00:00:00', tz='UTC')\n",
    "    print(since)\n",
    "    \n",
    "    is_end = False\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    chunk_no = 1\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        try:\n",
    "            response = requests.get(URL, params=params)\n",
    "            print(\"STATUS OF YOUR SCRAPING: chunk number\", chunk_no)\n",
    "            chunk_no += 1\n",
    "            response.close()\n",
    "        except:\n",
    "            print(\"An error occured.\" \n",
    "                  \"The http status code is {}\".format(response.status_code))\n",
    "        \n",
    "        toots = json.loads(response.text)\n",
    "    \n",
    "        if len(toots) == 0:\n",
    "            print(\"There were no toots returned. \" \n",
    "                  \"Check for spelling or use another hashtag\")\n",
    "            break\n",
    "        \n",
    "        for toot in toots:\n",
    "            timestamp = pd.Timestamp(toot['created_at'], tz='utc')\n",
    "            if timestamp <= since:\n",
    "                is_end = True\n",
    "                break\n",
    "                \n",
    "            results.append(toot)\n",
    "        \n",
    "        if is_end:\n",
    "            break\n",
    "        \n",
    "        max_id = toots[-1]['id']\n",
    "        params['max_id'] = max_id\n",
    "    \n",
    "        \n",
    "    df_hashtag = pd.DataFrame(results)\n",
    "    \n",
    "    return df_hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b724d8e-108f-4276-8544-e8053e523ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the hashtag which you would like to search:  IKEA\n",
      "Enter the Mastodon instance you would like to scrape. Good starting points are for example mastodon.social, mastodon.world. Make sure, you enter the entire name of the instance, e.g. mastodon.world. Instance of choice:  mastodon.social\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mastodon.social/api/v1/timelines/tag/ikea\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the date you would like to start scraping. Tip: Depending on the hashtag, start with a short time period. Use the YYYY-MM-DD notation:  2024-10-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 00:00:00+00:00\n",
      "STATUS OF YOUR SCRAPING: chunk number 1\n",
      "STATUS OF YOUR SCRAPING: chunk number 2\n",
      "STATUS OF YOUR SCRAPING: chunk number 3\n"
     ]
    }
   ],
   "source": [
    "df = scraping_toots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37d571-5398-4692-84a2-0c78e8140e0e",
   "metadata": {},
   "source": [
    "## Results and DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fab5250-3725-4391-ab72-4369ff1c80fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 24)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd72c9bd-1b5b-4e15-8716-1ffecc27a123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created_at', 'in_reply_to_id', 'in_reply_to_account_id',\n",
       "       'sensitive', 'spoiler_text', 'visibility', 'language', 'uri', 'url',\n",
       "       'replies_count', 'reblogs_count', 'favourites_count', 'edited_at',\n",
       "       'content', 'reblog', 'application', 'account', 'media_attachments',\n",
       "       'mentions', 'tags', 'emojis', 'card', 'poll'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494469e1-4146-4443-90ef-a5b221735108",
   "metadata": {},
   "source": [
    "## Cleaning up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ca16261-8d00-40fa-a632-1b4964ee7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def account_id_column(dataframe):\n",
    "    dataframe['account_id'] = dataframe['account'].apply(lambda x: x['id'])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81198287-e205-46f9-a919-bff52fa68458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_name_column(dataframe):\n",
    "\n",
    "    dataframe = dataframe.explode(\"tags\").reset_index()\n",
    "    dataframe[\"tag_name\"] = dataframe[\"tags\"].apply(lambda y: y['name'])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef102a68-e5e2-4632-b6fd-b8ab79f11116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_html(html):\n",
    "\n",
    "    \"\"\"Parsing a string which is in html code to extract actual text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    html : string\n",
    "        String that stores the content of the post (or any text) in html.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    soup.get_text() : string\n",
    "        A string with the actual text, without any html tags etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19be707b-c409-4718-938a-eca98f8326ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_content_column(dataframe):\n",
    "\n",
    "    dataframe[\"extracted_content\"] = dataframe[\"content\"].apply(extract_text_from_html)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "378142c3-fc71-441f-9b4c-f7c2f16fc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_languages():\n",
    "\n",
    "    defined_languages = False\n",
    "    \n",
    "    while True: \n",
    "        languages = input(\"Which languages should the posts have? \"\n",
    "                          \"Leave the field empty to use the default which is English. \"\n",
    "                          \"Otherwise refer to the List of ISO 639 language codes. \"\n",
    "                          \"Use the following way to write all of them down: en sv fr. \") or \"en\"\n",
    "        languages = languages.split(\" \")\n",
    "        print(\"Chosen languages: \", languages)\n",
    "        \n",
    "        answer = input(\"If these are the languages you want to use, type yes: \")\n",
    "        \n",
    "        if answer.lower() == \"yes\":\n",
    "            defined_languages = True\n",
    "            \n",
    "            print(\"Chosen languages are: \", languages)\n",
    "            break\n",
    "        \n",
    "    return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "443a8191-a285-4b22-921a-723610d83e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(dataframe):\n",
    "\n",
    "    dataframe = account_id_column(dataframe)\n",
    "    dataframe = tag_name_column(dataframe)\n",
    "    dataframe = parsed_content_column(dataframe)\n",
    "\n",
    "    \n",
    "    language_competences = [\"en\", \"de\", \"fr\", \"sv\"]\n",
    "    print(\"The following languages are used: \", language_competences)\n",
    "    language_answer = input(\"If you want to use the same languages, type yes, else type no: \")\n",
    "    \n",
    "    if language_answer.lower() != \"yes\":\n",
    "        language_competences = choose_languages()\n",
    "    \n",
    "    new = dataframe[dataframe['language'].isin(language_competences)]\n",
    "\n",
    "    \n",
    "    df_small = new[[\n",
    "    \"index\", \n",
    "    \"id\", \n",
    "    \"created_at\", \n",
    "    \"language\", \n",
    "    \"account_id\", \n",
    "    \"extracted_content\", \n",
    "    \"tag_name\"]]\n",
    "\n",
    "    return df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46edc3e9-032e-4f7b-994b-d8a569ca0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I used the following languages:  ['en', 'de', 'fr', 'sv']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "If you want to use the same languages, type yes, or else no:  no\n",
      "Which languages should the posts have? Leave the field empty to use the default which is English. Otherwise refer to the List of ISO 639 language codes. Use the following way to write all of them down: en sv fr.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen languages:  ['en']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "If these are the languages you want to use, type yes:  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen languages are:  ['en']\n"
     ]
    }
   ],
   "source": [
    "clean_df = cleaning_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dd09155-3bc2-4d6b-829c-65e5b328ae19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>113341403324783437</td>\n",
       "      <td>2024-10-20T19:29:25.386Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109358010895553496</td>\n",
       "      <td>Can we make #ikea #furniture also easy to disa...</td>\n",
       "      <td>ikea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>113341403324783437</td>\n",
       "      <td>2024-10-20T19:29:25.386Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109358010895553496</td>\n",
       "      <td>Can we make #ikea #furniture also easy to disa...</td>\n",
       "      <td>furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>113333960822788987</td>\n",
       "      <td>2024-10-19T11:56:41.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109284345361269535</td>\n",
       "      <td>My #HomeAssistant Green has been delayed. The ...</td>\n",
       "      <td>kodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>113333960822788987</td>\n",
       "      <td>2024-10-19T11:56:41.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109284345361269535</td>\n",
       "      <td>My #HomeAssistant Green has been delayed. The ...</td>\n",
       "      <td>picoreserver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>113333960822788987</td>\n",
       "      <td>2024-10-19T11:56:41.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109284345361269535</td>\n",
       "      <td>My #HomeAssistant Green has been delayed. The ...</td>\n",
       "      <td>ikea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>78</td>\n",
       "      <td>113238225913420391</td>\n",
       "      <td>2024-10-02T14:10:03.028Z</td>\n",
       "      <td>en</td>\n",
       "      <td>110428422327008517</td>\n",
       "      <td>Chytrá zásuvka INSPELNING vám pomůže hlídat sp...</td>\n",
       "      <td>chytradomacnost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>78</td>\n",
       "      <td>113238225913420391</td>\n",
       "      <td>2024-10-02T14:10:03.028Z</td>\n",
       "      <td>en</td>\n",
       "      <td>110428422327008517</td>\n",
       "      <td>Chytrá zásuvka INSPELNING vám pomůže hlídat sp...</td>\n",
       "      <td>chytrazasuvka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>78</td>\n",
       "      <td>113238225913420391</td>\n",
       "      <td>2024-10-02T14:10:03.028Z</td>\n",
       "      <td>en</td>\n",
       "      <td>110428422327008517</td>\n",
       "      <td>Chytrá zásuvka INSPELNING vám pomůže hlídat sp...</td>\n",
       "      <td>ikea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>78</td>\n",
       "      <td>113238225913420391</td>\n",
       "      <td>2024-10-02T14:10:03.028Z</td>\n",
       "      <td>en</td>\n",
       "      <td>110428422327008517</td>\n",
       "      <td>Chytrá zásuvka INSPELNING vám pomůže hlídat sp...</td>\n",
       "      <td>merenispotreby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>78</td>\n",
       "      <td>113238225913420391</td>\n",
       "      <td>2024-10-02T14:10:03.028Z</td>\n",
       "      <td>en</td>\n",
       "      <td>110428422327008517</td>\n",
       "      <td>Chytrá zásuvka INSPELNING vám pomůže hlídat sp...</td>\n",
       "      <td>zpravicky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                  id                created_at language  \\\n",
       "0        0  113341403324783437  2024-10-20T19:29:25.386Z       en   \n",
       "1        0  113341403324783437  2024-10-20T19:29:25.386Z       en   \n",
       "13       4  113333960822788987  2024-10-19T11:56:41.000Z       en   \n",
       "14       4  113333960822788987  2024-10-19T11:56:41.000Z       en   \n",
       "15       4  113333960822788987  2024-10-19T11:56:41.000Z       en   \n",
       "..     ...                 ...                       ...      ...   \n",
       "268     78  113238225913420391  2024-10-02T14:10:03.028Z       en   \n",
       "269     78  113238225913420391  2024-10-02T14:10:03.028Z       en   \n",
       "270     78  113238225913420391  2024-10-02T14:10:03.028Z       en   \n",
       "271     78  113238225913420391  2024-10-02T14:10:03.028Z       en   \n",
       "272     78  113238225913420391  2024-10-02T14:10:03.028Z       en   \n",
       "\n",
       "             account_id                                  extracted_content  \\\n",
       "0    109358010895553496  Can we make #ikea #furniture also easy to disa...   \n",
       "1    109358010895553496  Can we make #ikea #furniture also easy to disa...   \n",
       "13   109284345361269535  My #HomeAssistant Green has been delayed. The ...   \n",
       "14   109284345361269535  My #HomeAssistant Green has been delayed. The ...   \n",
       "15   109284345361269535  My #HomeAssistant Green has been delayed. The ...   \n",
       "..                  ...                                                ...   \n",
       "268  110428422327008517  Chytrá zásuvka INSPELNING vám pomůže hlídat sp...   \n",
       "269  110428422327008517  Chytrá zásuvka INSPELNING vám pomůže hlídat sp...   \n",
       "270  110428422327008517  Chytrá zásuvka INSPELNING vám pomůže hlídat sp...   \n",
       "271  110428422327008517  Chytrá zásuvka INSPELNING vám pomůže hlídat sp...   \n",
       "272  110428422327008517  Chytrá zásuvka INSPELNING vám pomůže hlídat sp...   \n",
       "\n",
       "            tag_name  \n",
       "0               ikea  \n",
       "1          furniture  \n",
       "13              kodi  \n",
       "14      picoreserver  \n",
       "15              ikea  \n",
       "..               ...  \n",
       "268  chytradomacnost  \n",
       "269    chytrazasuvka  \n",
       "270             ikea  \n",
       "271   merenispotreby  \n",
       "272        zpravicky  \n",
       "\n",
       "[85 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee90dc-bda9-4713-8b11-680708bbe4e2",
   "metadata": {},
   "source": [
    "## Having a closer look at the hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78cfdb-d321-47c7-b91d-7e41d155e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_count = df_small[\"tag_name\"].value_counts().reset_index()\n",
    "tags_count.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa142d-1bd1-43f4-8dda-a4906013dc88",
   "metadata": {},
   "source": [
    "**Some Notes**\n",
    "\n",
    "I recommend checking on hashtags, one does not understand - to get to know what's behind it. I checked on zpravicky, chytradomacnost, cesko and zigbee. The first three come from an account where langugae is marked as \"en\" but posts are in Czech. They come from the same account, going to drop the account. Not without checking beforehand if all the account's posts are actually in Czech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c4cdb-0861-4a05-aa2b-1157bfdadf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_to_drop = [\"110428422327008517\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5410e2b-0478-45ad-8ef8-78ed0c2cffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_small[df_small['account_id'].isin(accounts_to_drop) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c33cc6-55ba-4829-a32d-c4886fc30db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_count = df_small[\"tag_name\"].value_counts().reset_index()\n",
    "tags_count.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe5575-9d85-462b-ba91-894a78a25d7f",
   "metadata": {},
   "source": [
    "**Checking posts around sustainability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfffcb-adf9-4fe4-962a-8c155d85af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sustainability = [\"greenwashing\", \"klimaschutz\", \"klima\", \"umwelt\", \"umweltschutz\", \"nachhaltig\", \"nachhaltigkeit\", \"recycling\", \"deforestation\", \"environmental\", \"environment\", \"forets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9b2b2-579d-4a61-9e68-393c5997e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sustainable = df_small[df_small[\"tag_name\"].isin(sustainability)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7404c5d-74ef-4f1f-9251-2a35aec2285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as described before, explode() results in almost exact copies of some rows (except for tag name)\n",
    "# we only need the content once, to avoid duplicates utilizing drop_duplicates\n",
    "sustainable = df_sustainable.drop_duplicates(\"extracted_content\")[\"extracted_content\"].to_list()\n",
    "for post in sustainable[:10]:\n",
    "    print(post)\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f657a-b996-4fac-bc57-cbd624ad2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sustainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e91f2-7912-4d75-b947-c3d4a9156492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
