{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26516d7-6d92-470b-8800-934cef4d4f29",
   "metadata": {},
   "source": [
    "# Scraping Toots about Switzerland's Migros on Mastodon Social \n",
    "\n",
    "This notebook is a prototype on how to scrape messages - so called toots - from Mastodon with Python and Pandas. There are some functions for specific tasks, but mostly simple commands.\n",
    "\n",
    "It can be used as a walkthrough - one will find lots of explanations and also quite a few examples on how to clean the DataFrame and especially what to consider when working with the texts/ contents of the post. The formatting of the texts is soemtimes challenging and might cause problems with reliable analysis or techniques like word count etc.\n",
    "\n",
    "There are some results mentioned, but as there were not many posts with the hashtag Migros, it is only rudimentary. Even though my was not very informative, the folowwing technique is the same for any other hashtag and the code/ functions can be used accordingly for all hashtags. Have fun trying it out!\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "Mastodon is like Twitter, a free online service which allows you to send messages to thousands/ millions of people - especially your followers. What is the difference - Masatodon is not a croporate, imagine it as thousands of small Twitters, so called instances. Everyone can build an instance and host it. Some of these instances are public, but for most one has to demand access. We are going to scrape data from an open instance - the Social channel.\n",
    "\n",
    "When you are scraping from Mastodon consider these two things:\n",
    "\n",
    "1: Strict research rules are in place - whatever you do, do it in line with the Mastodon community: studies have been withdrawn because of privacy violations (Roel Roscam Abbing, Robert W. Gehl, 2024). This is especially true for the closed instances.\n",
    "\n",
    "2: Lots of instances have a public facing REST API for allowing users to interact with their services using third-party software. Which makes it very easy to scrape toots for a data project.\n",
    "\n",
    "So, it is easy to scrape data from Mastodon, but be ethical!\n",
    "\n",
    "Migros is Switzerland's largest retail company, its largest supermarket chain and largest employer. It is also one of the forty largest retailers in the world. It is structured in the form of a cooperative federation (the Federation of Migros Cooperatives), with more than two million members.\n",
    "\n",
    "Let's see what Mastodon \"toots\" about Migros!\n",
    "\n",
    "FYI: you can simply adapt this to your hashtag of choice, try it out! And it doesn't have to be a retailer, it can be anything like specific topics #globalwarming, #sustainability or feelings #joy, #sadness and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7c8981-4fe4-44f1-a5ea-01747572b5f4",
   "metadata": {},
   "source": [
    "## Load libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5668a5f8-60a7-49fa-a34b-866f8485fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fce9be-0d6f-4ebe-8b65-d26ac0a5906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk import bigrams (was not used with hashtag Migros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a62b36-1fba-469f-9d92-3c789260712c",
   "metadata": {},
   "source": [
    "## Preparation - Defining Hashtag and URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6886d3c-7933-4c9d-a2e8-f71f7dd03929",
   "metadata": {},
   "source": [
    "The hashtag you're interested in (in this case, 'migros').\n",
    "The API endpoint that returns posts with the given hashtag from Mastodon. We are scraping from Mastodon's social channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246a5710-c5aa-4d60-8834-065f6f407fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = 'migros'\n",
    "URL = f'https://mastodon.social/api/v1/timelines/tag/{hashtag}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a10bad-4ad9-49b7-b568-3a238170831b",
   "metadata": {},
   "source": [
    "## Browsing and scraping\n",
    "\n",
    "The following code now actually fetches recent posts with a specific hashtag from Mastodon and stores them in a Pandas DataFrame. See below for step by step description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d194dd01-a899-4df5-9cab-49f646485395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS OF YOUR SCRAPING\n",
      "OK - scraping of chunk no 1 worked.\n",
      "--------------------------------\n",
      "STATUS OF YOUR SCRAPING\n",
      "OK - scraping of chunk no 2 worked.\n",
      "--------------------------------\n",
      "STATUS OF YOUR SCRAPING\n",
      "OK - scraping of chunk no 3 worked.\n",
      "--------------------------------\n",
      "STATUS OF YOUR SCRAPING\n",
      "OK - scraping of chunk no 4 worked.\n",
      "--------------------------------\n",
      "STATUS OF YOUR SCRAPING\n",
      "OK - scraping of chunk no 5 worked.\n",
      "--------------------------------\n",
      "STATUS OF YOUR SCRAPING\n",
      "OK - scraping of chunk no 6 worked.\n",
      "--------------------------------\n",
      "STATUS OF YOUR SCRAPING\n",
      "OK - scraping of chunk no 7 worked.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "params = {'limit': 40}\n",
    "\n",
    "since = pd.Timestamp('2022-01-01 00:00:00', tz='UTC')\n",
    "is_end = False\n",
    "\n",
    "\n",
    "results = []\n",
    "chunk_no = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "        response = requests.get(URL, params=params)\n",
    "        print(\"STATUS OF YOUR SCRAPING\")\n",
    "        print(\"OK - scraping of chunk no {} worked.\".format(chunk_no))\n",
    "        print(\"--------------------------------\")\n",
    "        chunk_no += 1\n",
    "        response.close()\n",
    "    except:\n",
    "        print(\"An error occured.\" \n",
    "              \"The http status code is {}\".format(response.status_code))\n",
    "    \n",
    "    toots = json.loads(response.text)\n",
    "\n",
    "    if len(toots) == 0:\n",
    "        print(\"There were no toots returned. \" \n",
    "              \"Check for spelling or use another hashtag\")\n",
    "        break\n",
    "    \n",
    "    for toot in toots:\n",
    "        timestamp = pd.Timestamp(toot['created_at'], tz='utc')\n",
    "        if timestamp <= since:\n",
    "            is_end = True\n",
    "            break\n",
    "            \n",
    "        results.append(toot)\n",
    "    \n",
    "    if is_end:\n",
    "        break\n",
    "    \n",
    "    max_id = toots[-1]['id']\n",
    "    params['max_id'] = max_id\n",
    "\n",
    "    \n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43869c1-6c16-43d8-acd1-c845a4f16c80",
   "metadata": {},
   "source": [
    "Let's go through the code step by step:\n",
    "\n",
    "params = {'limit': 40} - I am going to work with Pythons requests library. The .get function requires an URL - which I already defined. Additional parameters are possible. I am going to work with params, which should be defined as dictionary. First key-value pair is 'limit':40. The API request will ask for a maximum of 40 posts in each request, which is due to the fact that the maximum value of toots that can be pulled at once is 40. Which also means, that the toots come in as chunks.\n",
    "\n",
    "since - interested in a certain timeframe, which is defined in the since variable. This has to be set as a timestamp.\n",
    "\n",
    "is_end - working with a loop to gather the toot chunks. is_end is a flag that will help terminate the loop once the condition is met (when no more recent posts are available).\n",
    "\n",
    "results - An empty list that will store the fetched posts (toots).\n",
    "\n",
    "chunk_no - a little extra for the loop; to count the chunk number and follow the process\n",
    "\n",
    "\n",
    "while True - while True loop is initiated to continuously send requests to the API. \n",
    "\n",
    "try - except with:\n",
    "\n",
    "    -- response = requests.get(URL, params=params) - sends a GET request to the Mastodon API.\n",
    "    -- print statement which lets you follow the status, adding 1 to chunk_no\n",
    "    -- except statement when something goes wrong - probably the http status code is not 200\n",
    "\n",
    "toots = json.loads(response.text) - converts the JSON response into a Python object (list of dictionaries). Only the .text attribute is stored.\n",
    "\n",
    "if len(toots) == 0: break - if there are no toots returned in the response, the loop terminates by using break. A statement is printed.\n",
    "\n",
    "for toot in toots: - The script loops over each toot in the response. For each toot: \n",
    "\n",
    "    -- timestamp: The creation time of the toot is converted into a pandas.Timestamp in UTC.\n",
    "    -- If the toot's timestamp is older than or equal to the since timestamp, the loop breaks, and the fetching ends (is_end  is set to True).\n",
    "    -- If the toot is within the timeframe, it is appended to the results list.\n",
    "\n",
    "max_id = toots[-1]['id'] and params['max_id'] = max_id - The last toot's ID (max_id) is stored. And we add max_id to the params dictionary. This way, I ensure that when the next iteration in the loop starts, I will get the next set of toots and not the same again. Saying: The max_id parameter tells the API to return posts older than the specified ID.\n",
    "\n",
    "if is_end: break - If is_end is set to True (i.e., a post older than the date set in since), the loop terminates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37d571-5398-4692-84a2-0c78e8140e0e",
   "metadata": {},
   "source": [
    "## Let's have a look at results - the DataFrame\n",
    "\n",
    "We saw before that with Mastodon Social providing RestAPI, it makes it super easy to retrieve information and it being stored in a DataFrame. Not all web scraping is that easy. Refer to my project \"Using Web Scraping for Your Hobby\" to get an impression how web scraping is conducted when no tool is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fab5250-3725-4391-ab72-4369ff1c80fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60443fe7-8a59-486f-a568-a5afd42c130c",
   "metadata": {},
   "source": [
    "As one can see, there are 24 columns - so there is a lot of variables - information stored. Let's have a look at these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd72c9bd-1b5b-4e15-8716-1ffecc27a123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created_at', 'in_reply_to_id', 'in_reply_to_account_id',\n",
       "       'sensitive', 'spoiler_text', 'visibility', 'language', 'uri', 'url',\n",
       "       'replies_count', 'reblogs_count', 'favourites_count', 'edited_at',\n",
       "       'content', 'reblog', 'application', 'account', 'media_attachments',\n",
       "       'mentions', 'tags', 'emojis', 'card', 'poll'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7fc92-8f00-43bf-b56c-ded174db2935",
   "metadata": {},
   "source": [
    "I am only interested in id, created_at, language, content, account, and tags. Here comes what needs to be considered:\n",
    "\n",
    "The column account stores values in a dictionary. All kind of info given by the user is stored (websites, note, avatar, emojis, etc.). I am only interested in the account id, which I will use later for some tiny cleaning up. If one wants to use any of the other info stored in account, please make sure to check what can be used and what not.\n",
    "\n",
    "content is stored as HTML code.\n",
    "\n",
    "The column tag is a list of dictionaries. I am interested in those, which is why I am using the explode() module on that column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494469e1-4146-4443-90ef-a5b221735108",
   "metadata": {},
   "source": [
    "## Cleaning up the data - respectively the DataFrame\n",
    "\n",
    "One will see, that there is a lot of cleaning up to do, especially when it comes the the text part of the post. The following will take the reader through the cleaning process but also some analysing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b5857-1bb9-48a3-ae4d-3662d91376bb",
   "metadata": {},
   "source": [
    "**First, let's extract the account id and build a small subset with only the columns of interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658d323c-b840-4a79-a976-d848d696eaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113311378195301884</td>\n",
       "      <td>2024-10-15T12:13:38.265Z</td>\n",
       "      <td>de</td>\n",
       "      <td>110995445679503453</td>\n",
       "      <td>&lt;p&gt;Werde wohl in Zukunft vermehrt bei den Mitb...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://social.tchncs.de/tags/Phis...</td>\n",
       "      <td>[{'name': 'phishing', 'url': 'https://mastodon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113282648729054678</td>\n",
       "      <td>2024-10-10T10:27:21.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109471764792431240</td>\n",
       "      <td>&lt;p&gt;Presse: Migros aurait payé des dizaines de ...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113266852927028084</td>\n",
       "      <td>2024-10-07T15:30:13.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros Luzern übernimmt Logistikleistungen ...</td>\n",
       "      <td>[{'name': 'genossenschaftmigrosluzern', 'url':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113264875250578179</td>\n",
       "      <td>2024-10-07T07:07:19.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109471764792431240</td>\n",
       "      <td>&lt;p&gt;Migros Tessin sera livré depuis Lucerne&lt;/p&gt;...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                created_at language          account_id  \\\n",
       "0  113311378195301884  2024-10-15T12:13:38.265Z       de  110995445679503453   \n",
       "1  113286497181684457  2024-10-11T02:46:03.000Z       de  109250689920748120   \n",
       "2  113282648729054678  2024-10-10T10:27:21.000Z       de  109471764792431240   \n",
       "3  113266852927028084  2024-10-07T15:30:13.000Z       de  109669545373361861   \n",
       "4  113264875250578179  2024-10-07T07:07:19.000Z       de  109471764792431240   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>Werde wohl in Zukunft vermehrt bei den Mitb...   \n",
       "1  <p><a href=\"https://social.tchncs.de/tags/Phis...   \n",
       "2  <p>Presse: Migros aurait payé des dizaines de ...   \n",
       "3  <p>Migros Luzern übernimmt Logistikleistungen ...   \n",
       "4  <p>Migros Tessin sera livré depuis Lucerne</p>...   \n",
       "\n",
       "                                                tags  \n",
       "0  [{'name': 'migros', 'url': 'https://mastodon.s...  \n",
       "1  [{'name': 'phishing', 'url': 'https://mastodon...  \n",
       "2  [{'name': 'migros', 'url': 'https://mastodon.s...  \n",
       "3  [{'name': 'genossenschaftmigrosluzern', 'url':...  \n",
       "4  [{'name': 'migros', 'url': 'https://mastodon.s...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['account_id'] = df['account'].apply(lambda x: x['id'])\n",
    "df_small = df[[\"id\", \"created_at\", \"language\", \"account_id\", \"content\", \"tags\"]]\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff9819f2-ee8f-437e-a3b4-4c7757d142d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            object\n",
       "created_at    object\n",
       "language      object\n",
       "account_id    object\n",
       "content       object\n",
       "tags          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40838bd-ff7b-4de1-b922-a1b87826d3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cceb75-2ab1-4770-8b7c-c552077c0cdc",
   "metadata": {},
   "source": [
    "**Languages**\n",
    "\n",
    "I would like to count the languages. It also shows, that some of the toots have a value in the language column, which does not align whith the language used in the content (text of the post), e.g. there are posts in German, which are marked as English. This is an important observation if one would like to work with only a certain language.\n",
    "\n",
    "While French, Italian and German make sense for posts about Migros in Switzerland, I will check on other languages a little closer. Most commonly used are btw German, English, French.\n",
    "\n",
    "(Note to self: try to find out, how the language is on Mastodon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c64690-234e-406a-908c-1c831ed793c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  count\n",
       "0       de    196\n",
       "1       en     27\n",
       "2       fr     23\n",
       "3       tr      5\n",
       "4       it      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small_languages = df_small[\"language\"].value_counts().reset_index()\n",
    "df_small_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f814009-60e8-4482-957d-05b8648f4042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>113160216482271211</td>\n",
       "      <td>2024-09-18T19:30:43.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109248094876977535</td>\n",
       "      <td>&lt;p&gt;…wann explodieren die &lt;a href=\"https://mast...</td>\n",
       "      <td>[{'name': 'grapefruits', 'url': 'https://masto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>112955272176224449</td>\n",
       "      <td>2024-08-13T14:51:08.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109682912434015779</td>\n",
       "      <td>&lt;p&gt;Genious from &lt;a href=\"https://tooting.ch/ta...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>112938769543445238</td>\n",
       "      <td>2024-08-10T16:54:18.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109256768253402788</td>\n",
       "      <td>&lt;p&gt;Dass die &lt;a href=\"https://tooting.ch/tags/M...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>112672687269848703</td>\n",
       "      <td>2024-06-24T17:06:07.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>110609296177745642</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://swiss.social/tags/Migros\" ...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>112654331960517178</td>\n",
       "      <td>2024-06-21T11:18:08.366Z</td>\n",
       "      <td>en</td>\n",
       "      <td>111260861347211991</td>\n",
       "      <td>&lt;p&gt;Liebe &lt;a href=\"https://mastodon.social/tags...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                created_at language          account_id  \\\n",
       "14  113160216482271211  2024-09-18T19:30:43.000Z       en  109248094876977535   \n",
       "28  112955272176224449  2024-08-13T14:51:08.000Z       en  109682912434015779   \n",
       "29  112938769543445238  2024-08-10T16:54:18.000Z       en  109256768253402788   \n",
       "45  112672687269848703  2024-06-24T17:06:07.000Z       en  110609296177745642   \n",
       "49  112654331960517178  2024-06-21T11:18:08.366Z       en  111260861347211991   \n",
       "\n",
       "                                              content  \\\n",
       "14  <p>…wann explodieren die <a href=\"https://mast...   \n",
       "28  <p>Genious from <a href=\"https://tooting.ch/ta...   \n",
       "29  <p>Dass die <a href=\"https://tooting.ch/tags/M...   \n",
       "45  <p><a href=\"https://swiss.social/tags/Migros\" ...   \n",
       "49  <p>Liebe <a href=\"https://mastodon.social/tags...   \n",
       "\n",
       "                                                 tags  \n",
       "14  [{'name': 'grapefruits', 'url': 'https://masto...  \n",
       "28  [{'name': 'migros', 'url': 'https://mastodon.s...  \n",
       "29  [{'name': 'migros', 'url': 'https://mastodon.s...  \n",
       "45  [{'name': 'migros', 'url': 'https://mastodon.s...  \n",
       "49  [{'name': 'migros', 'url': 'https://mastodon.s...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small_english_toots = df_small[df_small[\"language\"] == \"en\"]\n",
    "df_small_english_toots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131ba54-5d07-4097-94ba-0753f76d6d2b",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "There are some posts in English, which look like they actually have to to with Migros, the supermarket. But some of the posts marked with \"en\" are in fact written in German. I will keep \"en\" posts and check again on them later on.\n",
    "\n",
    "For solely language reasons, I will drop posts which are written in Turkish and Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ed9962-71ab-4c54-8400-6941bf2d6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_to_drop = [\"tr\", \"it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f5d21a-1562-4069-bab1-13c108532047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "de    196\n",
       "en     27\n",
       "fr     23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small_drop_languages = df_small[df_small['language'].isin(languages_to_drop) == False]\n",
    "df_small_drop_languages[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e7d07-2160-456b-99ce-e5c062e17fab",
   "metadata": {},
   "source": [
    "\n",
    "**You might want to skip the following step, if you're not using the migros hashtag - but check if you are facing a similar situation**\n",
    "\n",
    "It is always a good idea to browse the posts which have the researched hashtags on the Mastadon website - in this case Mastadon Social, to get a first impression.\n",
    "\n",
    "I realized, that there is an account which posts about all things business, entrepreneurship in Switzerland but always in German AND in French. It would obviously be the same content, so I decided to drop the account posting the message in French and to keep the one posting the content in German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d98ae10-9a3c-4502-9767-a08b9959895b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_drop = [\"109471764792431240\"]\n",
    "df_clean = df_small_drop_languages[df_small_drop_languages[\"account_id\"].isin(id_to_drop) == False]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b103f4a-a9b0-4c06-b6de-3532c2d2d514",
   "metadata": {},
   "source": [
    "**Using explode on the tags column**\n",
    "\n",
    "As mentioned before, the tags column is a list of dictionaries, which is why I am going to use the explode() function. Every dictionary contains information about one hashtag used in the post, included is the name and hashtag url. So number of hashtags = number of dictionaries in the list. \n",
    "\n",
    "What happens, when using explode: every dictionary (so every hashtag) get's its own row, while the values of the other columns are copied and stay the same. So every tag will end up on it's own line, which is why I will keep the index column, there I can easily follow which rows belonged to the same post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038fd97b-afce-4b1b-af06-435fa704fa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>113311378195301884</td>\n",
       "      <td>2024-10-15T12:13:38.265Z</td>\n",
       "      <td>de</td>\n",
       "      <td>110995445679503453</td>\n",
       "      <td>&lt;p&gt;Werde wohl in Zukunft vermehrt bei den Mitb...</td>\n",
       "      <td>{'name': 'migros', 'url': 'https://mastodon.so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://social.tchncs.de/tags/Phis...</td>\n",
       "      <td>{'name': 'phishing', 'url': 'https://mastodon....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://social.tchncs.de/tags/Phis...</td>\n",
       "      <td>{'name': 'migros', 'url': 'https://mastodon.so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://social.tchncs.de/tags/Phis...</td>\n",
       "      <td>{'name': 'cybercrime', 'url': 'https://mastodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>113266852927028084</td>\n",
       "      <td>2024-10-07T15:30:13.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros Luzern übernimmt Logistikleistungen ...</td>\n",
       "      <td>{'name': 'genossenschaftmigrosluzern', 'url': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>113266852927028084</td>\n",
       "      <td>2024-10-07T15:30:13.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros Luzern übernimmt Logistikleistungen ...</td>\n",
       "      <td>{'name': 'migros', 'url': 'https://mastodon.so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>113266852927028084</td>\n",
       "      <td>2024-10-07T15:30:13.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros Luzern übernimmt Logistikleistungen ...</td>\n",
       "      <td>{'name': 'news', 'url': 'https://mastodon.soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>113237114286084000</td>\n",
       "      <td>2024-10-02T09:27:20.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros-Tochter Galaxus baut neues Logistikz...</td>\n",
       "      <td>{'name': 'digitecgalaxusag', 'url': 'https://m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>113237114286084000</td>\n",
       "      <td>2024-10-02T09:27:20.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros-Tochter Galaxus baut neues Logistikz...</td>\n",
       "      <td>{'name': 'migros', 'url': 'https://mastodon.so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>113237114286084000</td>\n",
       "      <td>2024-10-02T09:27:20.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros-Tochter Galaxus baut neues Logistikz...</td>\n",
       "      <td>{'name': 'news', 'url': 'https://mastodon.soci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  id                created_at language  \\\n",
       "0      0  113311378195301884  2024-10-15T12:13:38.265Z       de   \n",
       "1      1  113286497181684457  2024-10-11T02:46:03.000Z       de   \n",
       "2      1  113286497181684457  2024-10-11T02:46:03.000Z       de   \n",
       "3      1  113286497181684457  2024-10-11T02:46:03.000Z       de   \n",
       "4      3  113266852927028084  2024-10-07T15:30:13.000Z       de   \n",
       "5      3  113266852927028084  2024-10-07T15:30:13.000Z       de   \n",
       "6      3  113266852927028084  2024-10-07T15:30:13.000Z       de   \n",
       "7      5  113237114286084000  2024-10-02T09:27:20.000Z       de   \n",
       "8      5  113237114286084000  2024-10-02T09:27:20.000Z       de   \n",
       "9      5  113237114286084000  2024-10-02T09:27:20.000Z       de   \n",
       "\n",
       "           account_id                                            content  \\\n",
       "0  110995445679503453  <p>Werde wohl in Zukunft vermehrt bei den Mitb...   \n",
       "1  109250689920748120  <p><a href=\"https://social.tchncs.de/tags/Phis...   \n",
       "2  109250689920748120  <p><a href=\"https://social.tchncs.de/tags/Phis...   \n",
       "3  109250689920748120  <p><a href=\"https://social.tchncs.de/tags/Phis...   \n",
       "4  109669545373361861  <p>Migros Luzern übernimmt Logistikleistungen ...   \n",
       "5  109669545373361861  <p>Migros Luzern übernimmt Logistikleistungen ...   \n",
       "6  109669545373361861  <p>Migros Luzern übernimmt Logistikleistungen ...   \n",
       "7  109669545373361861  <p>Migros-Tochter Galaxus baut neues Logistikz...   \n",
       "8  109669545373361861  <p>Migros-Tochter Galaxus baut neues Logistikz...   \n",
       "9  109669545373361861  <p>Migros-Tochter Galaxus baut neues Logistikz...   \n",
       "\n",
       "                                                tags  \n",
       "0  {'name': 'migros', 'url': 'https://mastodon.so...  \n",
       "1  {'name': 'phishing', 'url': 'https://mastodon....  \n",
       "2  {'name': 'migros', 'url': 'https://mastodon.so...  \n",
       "3  {'name': 'cybercrime', 'url': 'https://mastodo...  \n",
       "4  {'name': 'genossenschaftmigrosluzern', 'url': ...  \n",
       "5  {'name': 'migros', 'url': 'https://mastodon.so...  \n",
       "6  {'name': 'news', 'url': 'https://mastodon.soci...  \n",
       "7  {'name': 'digitecgalaxusag', 'url': 'https://m...  \n",
       "8  {'name': 'migros', 'url': 'https://mastodon.so...  \n",
       "9  {'name': 'news', 'url': 'https://mastodon.soci...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat = df_clean.explode(\"tags\").reset_index()\n",
    "df_flat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198e835-0e1a-46df-932d-c751e9649aee",
   "metadata": {},
   "source": [
    "**Cleaning a little more the tags column**\n",
    "\n",
    "The \"tags\" column includes the name of the tag as well as the url - which one could click to follow the hashtag... But I only need the name, which is also easier to grasp at first sight. The following code will create a new column \"tag_name\", I will drop the original \"tags\" column later on, when I create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2050c3da-4f14-4e80-9a6f-84c9aa0b24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat[\"tag_name\"] = df_flat[\"tags\"].apply(lambda y: y[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4ca17-ae1d-4242-a757-4361e772b0fb",
   "metadata": {},
   "source": [
    "**Extracting the text from the content column**\n",
    "\n",
    "As pointed out earlier, the \"content\" column is in HTML code. Defining a function which utilizes BeautifulSoup to parse the code. The apply() function will apply the defined function on every value in the specified column. Again, creating a new column \"extracted_content\" which stores the result. Going to drop the original \"content\" column in the next step - and create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef102a68-e5e2-4632-b6fd-b8ab79f11116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_html(html):\n",
    "\n",
    "    \"\"\"Parsing a string which is in html code to extract actual text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    html : string\n",
    "        String that stores the content of the post (or any text) in html.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    soup.get_text() : string\n",
    "        A string with the actual text, without any html tags etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return soup.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5468710d-7f10-45b9-b8e2-c09ae3b35088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat[\"extracted_content\"] = df_flat[\"content\"].apply(extract_text_from_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d98e0f-d465-45ce-b09e-fafed22f32f0",
   "metadata": {},
   "source": [
    "**Narrowing down the DataFrame again**\n",
    "\n",
    "Dropping the original \"tags\" and \"content\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "870f62c9-edf4-419c-a4e9-b5f0cea51266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat_small = df_flat[[\n",
    "    \"index\", \n",
    "    \"id\", \n",
    "    \"created_at\", \n",
    "    \"language\", \n",
    "    \"account_id\", \n",
    "    \"extracted_content\", \n",
    "    \"tag_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa6e4c7d-163a-46ed-8b7d-7a37efd3a9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>113311378195301884</td>\n",
       "      <td>2024-10-15T12:13:38.265Z</td>\n",
       "      <td>de</td>\n",
       "      <td>110995445679503453</td>\n",
       "      <td>Werde wohl in Zukunft vermehrt bei den Mitbewe...</td>\n",
       "      <td>migros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>#Phishing-Mail – Rückerstattung der #Migros - ...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>#Phishing-Mail – Rückerstattung der #Migros - ...</td>\n",
       "      <td>migros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>#Phishing-Mail – Rückerstattung der #Migros - ...</td>\n",
       "      <td>cybercrime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>113266852927028084</td>\n",
       "      <td>2024-10-07T15:30:13.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>Migros Luzern übernimmt Logistikleistungen für...</td>\n",
       "      <td>genossenschaftmigrosluzern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  id                created_at language  \\\n",
       "0      0  113311378195301884  2024-10-15T12:13:38.265Z       de   \n",
       "1      1  113286497181684457  2024-10-11T02:46:03.000Z       de   \n",
       "2      1  113286497181684457  2024-10-11T02:46:03.000Z       de   \n",
       "3      1  113286497181684457  2024-10-11T02:46:03.000Z       de   \n",
       "4      3  113266852927028084  2024-10-07T15:30:13.000Z       de   \n",
       "\n",
       "           account_id                                  extracted_content  \\\n",
       "0  110995445679503453  Werde wohl in Zukunft vermehrt bei den Mitbewe...   \n",
       "1  109250689920748120  #Phishing-Mail – Rückerstattung der #Migros - ...   \n",
       "2  109250689920748120  #Phishing-Mail – Rückerstattung der #Migros - ...   \n",
       "3  109250689920748120  #Phishing-Mail – Rückerstattung der #Migros - ...   \n",
       "4  109669545373361861  Migros Luzern übernimmt Logistikleistungen für...   \n",
       "\n",
       "                     tag_name  \n",
       "0                      migros  \n",
       "1                    phishing  \n",
       "2                      migros  \n",
       "3                  cybercrime  \n",
       "4  genossenschaftmigrosluzern  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee90dc-bda9-4713-8b11-680708bbe4e2",
   "metadata": {},
   "source": [
    "## Having a closer look at the hashtags\n",
    "\n",
    "I am going to use value_counts() on the \"tag_name\" column to count the appearance of each hashtag. Creating a new DataFrame with just the hashtags and their individual count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b78cfdb-d321-47c7-b91d-7e41d155e134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>migros</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coop</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schweiz</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>migrosbank</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>denner</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lebensmittel</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>micarna</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lidl</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SOCAR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nachhaltig</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mckinsey</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>specisme</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>konsum</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nachhaltigkeit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>switzerland</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>journalismus</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>greenwashing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>migrolino</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>migrolinotsocar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>einkaufen</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vegan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>abattoir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>environmental</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aldi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag_name  count\n",
       "0            migros    209\n",
       "1              news     52\n",
       "2              coop     28\n",
       "3           schweiz     22\n",
       "4        migrosbank      7\n",
       "5            denner      6\n",
       "6      lebensmittel      6\n",
       "7           micarna      6\n",
       "8              lidl      4\n",
       "9             SOCAR      4\n",
       "10       nachhaltig      4\n",
       "11         mckinsey      3\n",
       "12         specisme      3\n",
       "13           konsum      3\n",
       "14   nachhaltigkeit      3\n",
       "15      switzerland      3\n",
       "16     journalismus      3\n",
       "17     greenwashing      3\n",
       "18        migrolino      3\n",
       "19  migrolinotsocar      3\n",
       "20        einkaufen      3\n",
       "21            vegan      3\n",
       "22         abattoir      3\n",
       "23    environmental      2\n",
       "24             aldi      2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_count = df_flat_small[\"tag_name\"].value_counts().reset_index()\n",
    "tags_count.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90355d7f-ff52-40f7-be14-aa16d0550da2",
   "metadata": {},
   "source": [
    "**Result**\n",
    "\n",
    "So, there is not much interesting to see, but also: we now have a time frame from the 1st of January 2020 until newest and we have only 200+ posts, which ist not that much for that time frame. There are not many posts about Migros on Mastodon Social, which also shows in the hashtag counts. Things to do if you encounter that with your hashtag: try another open Mastodon channel or try and find an interesting instance, aks them if they are okay with scraping...\n",
    "\n",
    "Nevertheless - and the technique remains the same - we can now have an even closer look at certain hashtags. Of course, there is Migros on top - as we searched for that one. Then Coop - another Swiss supermarket (in fact, as well a big cooperative) - is mentioned quite often together with Migros. We have companies mentioned which belong to the cooperate: Denner, Micarna, Migrolino.\n",
    "\n",
    "**Investigating the sustainability topic**\n",
    "\n",
    "As sustainability is a big topic, I am interested in the posts which mention anything around that topic. I created a list with possible terms, which could be extended easily. Let's have a look at the content of these posts and see what people think. Maybe marketing or management can get some ideas on what could be tackled ;).\n",
    "\n",
    "I am storing the content (texts) in a seperate list and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e138ffd-1e68-4f0a-8628-71f75b15299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sustainability = [\"greenwashing\", \"klimaschutz\", \"klima\", \"umwelt\", \"umweltschutz\", \"nachhaltig\", \"nachhaltigkeit\", \"tier\", \"tierschutz\", \"recycling\", \"vegan\", \"environmental\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaffb384-8a3f-4cc7-9477-54d6de59835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sustainable = df_flat_small[df_flat_small[\"tag_name\"].isin(sustainability)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0935dd0d-1262-466d-bc2b-a85e7af33bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>91</td>\n",
       "      <td>111940164238040340</td>\n",
       "      <td>2024-02-16T08:15:47.000Z</td>\n",
       "      <td>fr</td>\n",
       "      <td>111052559215472401</td>\n",
       "      <td>Bonne nouvelle, le secteur de la viande n'est ...</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>131</td>\n",
       "      <td>111492923195380914</td>\n",
       "      <td>2023-11-29T08:36:35.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>715389</td>\n",
       "      <td>Milch-Alternativen anzubieten, die nicht das d...</td>\n",
       "      <td>klimaschutz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>145</td>\n",
       "      <td>111256434458160431</td>\n",
       "      <td>2023-10-18T14:14:19.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>110782341900638100</td>\n",
       "      <td>Does any of the #swiss #vegan folks around her...</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>147</td>\n",
       "      <td>111220640509446225</td>\n",
       "      <td>2023-10-12T06:31:27.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109332839915149747</td>\n",
       "      <td>Die #Migros Greenwashing Kampagne geht weiter....</td>\n",
       "      <td>recycling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>174</td>\n",
       "      <td>110656732208551487</td>\n",
       "      <td>2023-07-04T16:22:15.126Z</td>\n",
       "      <td>en</td>\n",
       "      <td>109246062752827438</td>\n",
       "      <td>Nach dem #SRK ein weiteres Schweizer #NGO in d...</td>\n",
       "      <td>tierschutz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                  id                created_at language  \\\n",
       "226     91  111940164238040340  2024-02-16T08:15:47.000Z       fr   \n",
       "352    131  111492923195380914  2023-11-29T08:36:35.000Z       de   \n",
       "393    145  111256434458160431  2023-10-18T14:14:19.000Z       en   \n",
       "402    147  111220640509446225  2023-10-12T06:31:27.000Z       de   \n",
       "492    174  110656732208551487  2023-07-04T16:22:15.126Z       en   \n",
       "\n",
       "             account_id                                  extracted_content  \\\n",
       "226  111052559215472401  Bonne nouvelle, le secteur de la viande n'est ...   \n",
       "352              715389  Milch-Alternativen anzubieten, die nicht das d...   \n",
       "393  110782341900638100  Does any of the #swiss #vegan folks around her...   \n",
       "402  109332839915149747  Die #Migros Greenwashing Kampagne geht weiter....   \n",
       "492  109246062752827438  Nach dem #SRK ein weiteres Schweizer #NGO in d...   \n",
       "\n",
       "        tag_name  \n",
       "226        vegan  \n",
       "352  klimaschutz  \n",
       "393        vegan  \n",
       "402    recycling  \n",
       "492   tierschutz  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sustainable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7404c5d-74ef-4f1f-9251-2a35aec2285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonne nouvelle, le secteur de la viande n'est plus en expansion en Suisse, et l'enseigne Micarna de Migros se voit contrainte de réduire la voilure. Cela est dû à un recul de «la consommation de viande fraîche, ce qui a un impact sur la production.»🔥 Les animaux ne sont pas des biens de consommation: abolissons la viande et tous les produits issus de l'exploitation animale!https://www.rts.ch/info/regions/vaud/2024/article/migros-va-fermer-son-site-micarna-a-ecublens-84-emplois-sont-menaces-28404819.html#micarnage #migros #vegan #antispecisme #vegane\n",
      "---------------------------------------------\n",
      "Milch-Alternativen anzubieten, die nicht das doppelte oder dreifache kosten, von #Kuhmilch war wohl der wichtigste Beitrag von #Migros und #Coop für den #Klimaschutz in diesem Jahr.Wermutstropfen: Es ist natürlich Sojamilch, für die vermutlich Regenwald gerodet wurde. Nicht Hafer, der auch ausserhalb der Tropen wächst. Aber 90% von diesem #Soja gehen ja in die #Viehwirtschaft, die noch riesige Mengen an Umweltbelastung obendrauf packt. Hier wird es wenigstens direkt an Menschen verkauft\n",
      "---------------------------------------------\n",
      "Does any of the #swiss #vegan folks around here know if the \"I am\" shaving brush from #migros is made from animal products or if it's synthetic? The packaging does not say anything useful.\n",
      "---------------------------------------------\n",
      "Die #Migros Greenwashing Kampagne geht weiter. Die blaue Öko-Recycling-Flasche kam bei den Kunden so gut an, dass sie fix im Sortiment bleibt.Auf die Idee Nachfüllbeutel zu verkaufen, damit man seine Flasche (egal ob recyclet oder nicht) wieder auffüllen kann statt immer eine neue Flasche zu kaufen kam man dann aber noch nicht 🙄#schweiz #recycling\n",
      "---------------------------------------------\n",
      "Nach dem #SRK ein weiteres Schweizer #NGO in der Kritik: „Schweizer #Tierschutz kuscht vor #Migros und #Coop“ #STS #Schweiz #nonprofithttps://www.srf.ch/news/wirtschaft/hohe-preise-fuer-bioware-schweizer-tierschutz-kuscht-vor-migros-und-coop\n",
      "---------------------------------------------\n",
      "Finde den Fehler!5 Jahre alte #Migros vs. neue #Rewe Tasche.100% vs. 36% :mastodon:  #nachhaltig #recycling #Plastik #pet #greenwashing @rewe\n",
      "---------------------------------------------\n",
      "Die #Migros lässt sich auf #socialmedia dafür feiern das sie ihr beliebtes Spülmittel nun in einer „Limited“ Version verkaufen - aus #plastik das aus den Meeren gefischt wurde.Sas ganze kostet 30 Rappen mehr als das normale Spülmittel.Ist es nun die Idee weiter Plastik zu produzieren, diesen in den Ozeanen zu entsorgen, den aufwendig wieder rausfischen und das die Konsumenten mit „Special Editionen“ bezahlen zu lassen? WTF? Wer denkt sich sowas aus?#klima #umwelt #plastik #Schweiz\n",
      "---------------------------------------------\n",
      "Was bedeutet #nachhaltig, #klimaneutral oder #natürlich? @ErichBuergler berichtet in der @sonntagszeitung über unsere Kritik an der #Werbung von #Migros und #Coop(Abo-Artikel).https://www.tagesanzeiger.ch/greenpeace-wirft-migros-und-coop-greenwashing-vor-243204184726\n",
      "---------------------------------------------\n",
      "#Werbung ist omnipräsent - und hat Einfluss auf #Klima und #Umwelt : Sie normalisiert den Konsum von Produkten, die unserem Planeten und der Gesellschaft schaden. Und sie steigert die Kauflust.In der 🇨🇭 geben #Migros und #Coop mit Abstand am meisten Geld aus für Werbung.\n",
      "---------------------------------------------\n",
      "« Die grünen Werbeslogans von #migros und #coop  sind laut der Umweltschutzorganisation Greenpeace undurchsichtig. Auch die Wissenschaft kritisiert das Marketing von Schweizer Unternehmen.#lebensmittel #detailhandel #nachhaltig #nachhaltigkeit https://lnkd.in/eASV8eM6 »— Retweet https://twitter.com/ErichBuergler/status/1647532695696572417\n",
      "---------------------------------------------\n",
      "#satire #cartoon #migros #greenwashing #umweltverschmutzung\n",
      "---------------------------------------------\n",
      "Heute #Burger Battle - mit ordentlicher #Verpackung 😉#BeyondMeat vs. #Migros vLove Eigenmarke.Sind beide empfehlenswert. Ungesunde Ernährung geht auch #vegan 🤪\n",
      "---------------------------------------------\n",
      "Neu auf #Infosperber:Trauben aus Namibia, Heidelbeeren aus Chile, Limetten aus Kolumbien: Lebensmittel vom anderen Ende der Welt entsprechen laut Detailhändlern einem «Kundenbedürfnis». Doch das ist offenbar nicht sehr gross. Mit Aktionen müssen die Detailhändler nachhelfen.https://www.infosperber.ch/wirtschaft/konsum/jetzt-brauchts-auch-noch-aktionen/#News #Journalismus #Infosperber #Migros #Coop #Aldi #Lidl #Denner #greenwashing\n",
      "---------------------------------------------\n",
      "Martin #Jucker von der Jucker #Farm wirft der #Migros vor, das eigene #Nachhaltigkeitsprogramm zu zerstören.https://www.zueritoday.ch/zuerich/top-aktionen-aus-aller-welt-bringen-juckerfarm-besitzer-in-rage-149461482#ZüriToday #JuckerFarm #Regional #Nachhaltig #Nachhaltigkeit #Lebensmittel\n",
      "---------------------------------------------\n",
      "@squirrelnews_en I've wondered when this #coffee #innovation would be developed..'Innovation' in quotations, as it's actually returning to basics ~ it's like a 'coffee pod' you get after making #espresso, except in reverse!Well done #Migros 👏🏽Thank you for the great news! Hope it takes off as it should 🙌🏽🙏🏽🙌🏽#cafe #caffe #food #waste #convenience #compost #biodegradable #climate #ClimateChange #ClimateCrisis #environment #environmental #Earth #awareness #mindfulness #consumption #consumerism\n",
      "---------------------------------------------\n",
      "The #coffee capsule market is dominated by #Nespresso, #lavazza, #Starbucks & #Gourmesso...all contributing to #environmental waste, excessive cost in the name of \"convenience\". To combat this, the leading Swiss supermarket #Migros  has developed a \"coffee ball.\" As the name suggests, it's simply a ball of coffee grinds contained by a biodegradable natural wrap. All coffee, no capsule, no waste! Read more 👇:https://www.foodnavigator.com/Article/2022/11/17/coffee-balls-replace-capsules-to-revolutionise-single-serve-coffee?utm_source=copyright&utm_medium=OnSite&utm_campaign=copyright\n",
      "---------------------------------------------\n",
      "Wer es mit der #Nachhaltigkeit ernst meint, verkauft kein Benzin - und erst recht nicht aus einem so korrupten Land. „Kooperation mit #Socar: Organisationen lancieren Appell an die #Migros“https://www.blick.ch/wirtschaft/kooperation-mit-socar-organisationen-lancieren-appell-an-die-migros-id18050872.html?utm_source=campaign&utm_medium=email&utm_campaign=share-button&utm_term=blick_app_ios\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# as described before, explode() results in almost exact copies of some rows (except for tag name)\n",
    "# we only need the content once, to avoid duplicates utilizing drop_duplicates\n",
    "sustainable = df_sustainable.drop_duplicates(\"extracted_content\")[\"extracted_content\"].to_list()\n",
    "for post in sustainable:\n",
    "    print(post)\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52efeff0-b454-45db-b810-0065885f95fb",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "\n",
    "There are as expected not many posts around these topics, as there are not many posts with hashtag Migros to begin with. Still, one can see that greenwashing is a discussion Migros could engage with. Or things like do they really act sustainable when at the same time selling gas, having misleading commercials, not so ecofriendly packaging as stated, importing fruits from all over the world etc. But there are positive statements: in the actual english written posts they applaude the coffee capsule made from coffee, and they mention that a milk alternative is sold, which is not 2-3 times more expensive than actual milk.\n",
    "\n",
    "Formatting/ grammar: There are a lot of cases where a space between two seperate words is missing. It appears as well, when there is a punctuation and a new word starts. This is probelamtic, when you want to count words, use any technique where frequencies of words are counted.\n",
    "\n",
    "**Schlachthof story**\n",
    "\n",
    "One can read about the Schlachthof story here: https://www.tagesanzeiger.ch/migros-streit-um-schlachthof-bringt-saint-aubin-ans-limit-562170273054 and here https://www.nzz.ch/wirtschaft/nachfrage-explodiert-bauern-schieben-nachtschichten-auslaendische-lieferanten-am-anschlag-der-schweiz-droht-ein-poulet-notstand-ld.1850348 \n",
    "\n",
    "This is an example how specific topics could be researched. The reaction on Mastodon Social around this topic highlights environmental considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb96b8a5-32a5-4740-8ae7-4fcaf4a5b533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>179</td>\n",
       "      <td>110615042718162477</td>\n",
       "      <td>2023-06-27T07:40:02.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>386737</td>\n",
       "      <td>#Schlachthof #Migros: Die Gemeinde St-Aubin ha...</td>\n",
       "      <td>schlachthof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>206</td>\n",
       "      <td>110144756385512536</td>\n",
       "      <td>2023-04-05T06:20:02.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>386737</td>\n",
       "      <td>#Migros plant mit ihrer Tochtergesellschaft #M...</td>\n",
       "      <td>schlachthof</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                  id                created_at language account_id  \\\n",
       "503    179  110615042718162477  2023-06-27T07:40:02.000Z       en     386737   \n",
       "575    206  110144756385512536  2023-04-05T06:20:02.000Z       en     386737   \n",
       "\n",
       "                                     extracted_content     tag_name  \n",
       "503  #Schlachthof #Migros: Die Gemeinde St-Aubin ha...  schlachthof  \n",
       "575  #Migros plant mit ihrer Tochtergesellschaft #M...  schlachthof  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_schlachthof = df_flat_small[df_flat_small[\"tag_name\"] == \"schlachthof\"]\n",
    "df_schlachthof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a7357eb-5992-42c6-a493-707233578942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Schlachthof #Migros: Die Gemeinde St-Aubin hat unsere Einsprache abgelehnt. Wir legen nun beim Kanton Freiburg Rekurs ein. Gemeinde und Kanton sollten der Umwelt Priorität einräumen können, nicht den wirtschaftlichen Interessen der Migros-Gruppe.https://act.gp/442XspQ\n",
      "---------------------------------------------\n",
      "#Migros plant mit ihrer Tochtergesellschaft #Micarna, einen gigantischen #Schlachthof im Herzen der Westschweiz zu bauen. 🐔 40 Millionen Hühner sollen da jährlich getötet werden. 🐔Wir stellen uns gegen dieses umwelt- und klimaschädliche Projekt. 👇https://act.gp/3zu7qCZ\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "schlachthof = df_schlachthof[\"extracted_content\"].to_list()\n",
    "for post in schlachthof:\n",
    "    print(post)\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64346ee4-a43b-4166-ab5b-b9429f5c2278",
   "metadata": {},
   "source": [
    "**Posts marked with language English**\n",
    "\n",
    "As I mentioned before, I wanted to have a closer look at posts which are marked with language \"en\". Extracting these now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "803f657a-b996-4fac-bc57-cbd624ad2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df_flat_small[df_flat_small[\"language\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ab7cf-30ab-4bc4-b66b-3866468137d5",
   "metadata": {},
   "source": [
    "**Printing the English posts**\n",
    "\n",
    "Only printing the first eight posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd2fb850-280c-4236-9ab3-ae49897db23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "…wann explodieren die #Grapefruits #Mangos und #Datteln aus #Israel ?#COOP #Migros\n",
      "---------------------------------------------\n",
      "Genious from #migros #playmobil\n",
      "---------------------------------------------\n",
      "Dass die #Migros bei Rückgabe von gekaufter Ware #Geschenkkarten statt #Geld raus gibt, ist ein Schuss in den Ofen #Kundenfreundlichkeit :blobfoxdisputed:\n",
      "---------------------------------------------\n",
      "#Migros #Coop #KTipp https://www.instagram.com/p/C8mhNMUqYUn/„Die Detailhändler verlangen für «regionale Produkte» oft überhöhte Preise.Der Zuschlag, den die Konsumenten zahlen, landet aber nicht bei den Bauern, sondern bei Coop, Migros & Co.“\n",
      "---------------------------------------------\n",
      "Liebe #Migros, toll, dass ihr auf #Verpackungen verzichtet. Bei der #Herkunftsangabe hätten wir aber noch einen Verbesserungsvorschlag... #GurkenDetektiv #MigrosFail\n",
      "---------------------------------------------\n",
      "Interessant: Die lokale (kleine) #Migros hatte auch von #OSRAM noch ein paar LEDs #MadeInGermany. Waren wohl aber nur ein Restposten, die neuer wirkenden Packungen ziert alle ein #MadeInChina.\n",
      "---------------------------------------------\n",
      "…#COOP #Migros etc., verkauft Ihr immer noch Früchte, gewachsen auf gestohlenem Land, bewässert mit gestohlenem Wasser?#Hehlerei\n",
      "---------------------------------------------\n",
      "#Migros, Switzerland's largest retail cooperative (not profit-oriented !!!), founded ~100 years ago, largest supermarket chain and largest employer (~100k employees).2023: record turnover of CHF 31.9 (USD 36.79) billion.CEO announced the sale of at least four subsidiaries: 6500 employees affect. In addition, up to 1500 jobs will be cut.I have a very different view of a cooperative... especially if there is no need for job cuts...#NotMyMigros\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "english = df_english.drop_duplicates(\"extracted_content\")[\"extracted_content\"].to_list()\n",
    "for post in english[:8]:\n",
    "    print(post)\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6b272-2134-41d7-829d-7569f5117292",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "\n",
    "The result shows, that for quite a few of them the content is not written in English, but in German and also in French. Those written in English have to do with Migros the supermarket.\n",
    "\n",
    "Someone highlights the Migros coffeemachine with pods made of coffee - a biodegradable alternative.\n",
    "\n",
    "**FYI**\n",
    "\n",
    "There might be more posts around the topics of environment and sustainability, they just don't use it in a hashtag. This is true for any topic, be it critical review or praise for a specific product/ campaign. Which is why looking into the actual content will provide more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3e43c-b6ad-4b8b-9506-0ffe3327d9b0",
   "metadata": {},
   "source": [
    "## Investigating the Content of the Posts\n",
    "\n",
    "There are several things one can do. First, word counts and also bigrams which show frequencies of the words used in the texts. I would add the actual word it self - if one wants to find toots around the topic of sustainability, they could prepare a list of words which are used in that context and search the texts for those words (example below). This way one can find toots discussing the topic sustainability but not using it in hashtags.\n",
    "\n",
    "Another step is, to automate a sentiment analysis on the content, to see if posts are rather positive or negative.\n",
    "\n",
    "Let's start with number one. I will work with the DataFrame df_clean, as I don't need every single hashtag, I only need the content. Still, I will utilize BeautifulSoup to parse the HTML code and I will clean up the tags column. Here is the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c6486a1-cf94-4ad3-b2a4-cf68101263bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113311378195301884</td>\n",
       "      <td>2024-10-15T12:13:38.265Z</td>\n",
       "      <td>de</td>\n",
       "      <td>110995445679503453</td>\n",
       "      <td>&lt;p&gt;Werde wohl in Zukunft vermehrt bei den Mitb...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://social.tchncs.de/tags/Phis...</td>\n",
       "      <td>[{'name': 'phishing', 'url': 'https://mastodon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113266852927028084</td>\n",
       "      <td>2024-10-07T15:30:13.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros Luzern übernimmt Logistikleistungen ...</td>\n",
       "      <td>[{'name': 'genossenschaftmigrosluzern', 'url':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113237114286084000</td>\n",
       "      <td>2024-10-02T09:27:20.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros-Tochter Galaxus baut neues Logistikz...</td>\n",
       "      <td>[{'name': 'digitecgalaxusag', 'url': 'https://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>113231137343913719</td>\n",
       "      <td>2024-10-01T08:07:19.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>&lt;p&gt;Migros schliesst Bestsmile&lt;/p&gt;&lt;p&gt;Die Migros...</td>\n",
       "      <td>[{'name': 'migros', 'url': 'https://mastodon.s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                created_at language          account_id  \\\n",
       "0  113311378195301884  2024-10-15T12:13:38.265Z       de  110995445679503453   \n",
       "1  113286497181684457  2024-10-11T02:46:03.000Z       de  109250689920748120   \n",
       "3  113266852927028084  2024-10-07T15:30:13.000Z       de  109669545373361861   \n",
       "5  113237114286084000  2024-10-02T09:27:20.000Z       de  109669545373361861   \n",
       "7  113231137343913719  2024-10-01T08:07:19.000Z       de  109669545373361861   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>Werde wohl in Zukunft vermehrt bei den Mitb...   \n",
       "1  <p><a href=\"https://social.tchncs.de/tags/Phis...   \n",
       "3  <p>Migros Luzern übernimmt Logistikleistungen ...   \n",
       "5  <p>Migros-Tochter Galaxus baut neues Logistikz...   \n",
       "7  <p>Migros schliesst Bestsmile</p><p>Die Migros...   \n",
       "\n",
       "                                                tags  \n",
       "0  [{'name': 'migros', 'url': 'https://mastodon.s...  \n",
       "1  [{'name': 'phishing', 'url': 'https://mastodon...  \n",
       "3  [{'name': 'genossenschaftmigrosluzern', 'url':...  \n",
       "5  [{'name': 'digitecgalaxusag', 'url': 'https://...  \n",
       "7  [{'name': 'migros', 'url': 'https://mastodon.s...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dd1b89f-8116-4a7b-9b61-def7a6c1eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid warnings and working in a neat way, creating a deep copy\n",
    "df_clean_copy = df_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdec28-e9a1-46a3-8e99-73d1f67473d6",
   "metadata": {},
   "source": [
    "**As before: parsing HTML code to get only text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abba398f-adb3-4f2d-ab09-2ca4df739449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_copy[\"extracted_content\"] = df_clean_copy[\"content\"].apply(extract_text_from_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11f950-dfe7-4527-bd58-1c178d3b219a",
   "metadata": {},
   "source": [
    "**Storing only tag names in list**\n",
    "\n",
    "I want to replace the tags column, this time with a column storing a list with all the hashtags used in the toot. I am only interested in the name, not the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c311fc4-339f-42d4-9c1f-c823535a77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tag_names(tags_list):\n",
    "    \n",
    "    \"\"\"Iterating through the list of tag dictionaries to extract the tag name.\n",
    "    Appending names to a new list. Dropping everything else.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tags_list : list\n",
    "        A list of dictionaries that you want to iterate through, to get tag names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tag_names : list\n",
    "        A list with only the names of the tags\n",
    "    \"\"\"\n",
    "\n",
    "    tag_names = []\n",
    "    for tag in tags_list:\n",
    "        tag_names.append(tag.get(\"name\"))\n",
    "\n",
    "    return tag_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617f952-0aaa-4772-a063-e225cc9f9f8f",
   "metadata": {},
   "source": [
    "**Creating the tags_name column in our DataFrame**\n",
    "\n",
    "Utilizing the before defined function. Dropping the original columns \"content\" and \"tags\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5b91fe5-4450-4347-9302-7a4dfa2013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_copy[\"tags_name\"] = df_clean_copy[\"tags\"].apply(extract_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d13ac87-40db-4ff8-a3cb-08a246a2a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_copy = df_clean_copy[[\n",
    "    \"id\", \n",
    "    \"created_at\", \n",
    "    \"language\", \n",
    "    \"account_id\", \n",
    "    \"extracted_content\", \n",
    "    \"tags_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7cc2d73-c8e2-4903-9f3b-d210527fadbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>account_id</th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>tags_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113311378195301884</td>\n",
       "      <td>2024-10-15T12:13:38.265Z</td>\n",
       "      <td>de</td>\n",
       "      <td>110995445679503453</td>\n",
       "      <td>Werde wohl in Zukunft vermehrt bei den Mitbewe...</td>\n",
       "      <td>[migros]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113286497181684457</td>\n",
       "      <td>2024-10-11T02:46:03.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109250689920748120</td>\n",
       "      <td>#Phishing-Mail – Rückerstattung der #Migros - ...</td>\n",
       "      <td>[phishing, migros, cybercrime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113266852927028084</td>\n",
       "      <td>2024-10-07T15:30:13.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>Migros Luzern übernimmt Logistikleistungen für...</td>\n",
       "      <td>[genossenschaftmigrosluzern, migros, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113237114286084000</td>\n",
       "      <td>2024-10-02T09:27:20.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>Migros-Tochter Galaxus baut neues Logistikzent...</td>\n",
       "      <td>[digitecgalaxusag, migros, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>113231137343913719</td>\n",
       "      <td>2024-10-01T08:07:19.000Z</td>\n",
       "      <td>de</td>\n",
       "      <td>109669545373361861</td>\n",
       "      <td>Migros schliesst BestsmileDie Migros gibt ihre...</td>\n",
       "      <td>[migros, news]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                created_at language          account_id  \\\n",
       "0  113311378195301884  2024-10-15T12:13:38.265Z       de  110995445679503453   \n",
       "1  113286497181684457  2024-10-11T02:46:03.000Z       de  109250689920748120   \n",
       "3  113266852927028084  2024-10-07T15:30:13.000Z       de  109669545373361861   \n",
       "5  113237114286084000  2024-10-02T09:27:20.000Z       de  109669545373361861   \n",
       "7  113231137343913719  2024-10-01T08:07:19.000Z       de  109669545373361861   \n",
       "\n",
       "                                   extracted_content  \\\n",
       "0  Werde wohl in Zukunft vermehrt bei den Mitbewe...   \n",
       "1  #Phishing-Mail – Rückerstattung der #Migros - ...   \n",
       "3  Migros Luzern übernimmt Logistikleistungen für...   \n",
       "5  Migros-Tochter Galaxus baut neues Logistikzent...   \n",
       "7  Migros schliesst BestsmileDie Migros gibt ihre...   \n",
       "\n",
       "                                    tags_name  \n",
       "0                                    [migros]  \n",
       "1              [phishing, migros, cybercrime]  \n",
       "3  [genossenschaftmigrosluzern, migros, news]  \n",
       "5            [digitecgalaxusag, migros, news]  \n",
       "7                              [migros, news]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60078e3-436e-4310-905d-57fa11ef0afe",
   "metadata": {},
   "source": [
    "**Only keeping toots with language = de**\n",
    "\n",
    "For the following steps I am going to work with word counts as well as dropping stopwords, and therefore sticking to just one language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e7a03ef-2f34-408f-ab3e-22d40963edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_copy = df_clean_copy[df_clean_copy['language'] == 'de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df4d9f84-1bc0-4eb0-b64a-43087bdba566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "de    156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_copy[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e343f-b64b-4989-aa12-513d4ff90f78",
   "metadata": {},
   "source": [
    "**Storing the toots in a seperate list**\n",
    "\n",
    "I will also remove any other URLs before starting to count the words, because it's simply not needed. URLs will not be analysed in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57de1dbf-7b59-4078-99f2-7261a96e7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "toots = df_clean_copy[\"extracted_content\"].to_list()\n",
    "#toots[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ce1a26a-5805-4235-a1d2-e7424f4edf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    \"\"\"Replace URLs found in a text string with nothing.\n",
    "    It will remove the URL from the string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : string\n",
    "        A text string that you want to parse and remove urls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The same txt string with url's removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    no_url = url_pattern.sub(r'', txt)\n",
    "\n",
    "    return no_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93c9d6c4-6ef9-4479-acea-55ead258b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toots_no_urls = [remove_url(toot) for toot in toots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb3e598b-17db-4252-a346-12223a5ef7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Werde wohl in Zukunft vermehrt bei den Mitbewerbern einkaufen… Ein Diebstahl muss vorsätzlich passieren und dies scheint hier nicht der Fall zu sein… #Migros'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toots_no_urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746ce6c-2b16-43bc-8911-e2fcbe3d63a7",
   "metadata": {},
   "source": [
    "**Splitting each toot in it's individual words**\n",
    "\n",
    "The following step splits each toot in it's individual words. The result is stored in a list per toot, which means words_in_toots is a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "140ae5e8-fd9e-4041-af7c-7275f421756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_toots = [toot.split() for toot in toots_no_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be26c7a-134a-4ac9-b3a0-f9eed0952a12",
   "metadata": {},
   "source": [
    "**Cleaning missing spaces**\n",
    "\n",
    "While browsing the texts, I realised that sometimes there was missing a space between two individual words, check for instance words_in_toots[3] - \"BestsmileDie\". The following function will take care of that observation. Be aware that words_in_toots is a list of lists. Which is why the function works with to for loops and two temporary lists. The function will again give out a list of lists.\n",
    "\n",
    "There is an exception for two cases: if a string is a hashtag, it is left as is, even if there are capital letters somewhere in the middle of the word/ string. It is important that hashtags stay as hashtags, otherwise they would be split and no longer be the correct hashtag. (example: #ILikeCoffee). If a word/ string is written in all capital letters (because it's an abbreviation or people want to highlight certain words), it will not be split - it would result all single letters and that is not correct (example: das ist NICHT okay - the word NICHT shouldn't be split because of what the function is doing otherwise, splitting when there is a capital letter midst in the string). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceed42a0-b512-4c7b-9609-6081e6f51a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_spaces(toot_list):\n",
    "    \n",
    "    \"\"\"Seperate two individual words from each other where a space is missing.\n",
    "    It will search for cases where there is a capital letter midst in a string.\n",
    "    In probably most cases that means, that there is a space missing.\n",
    "    It does not apply, when the string is a hashtag. \n",
    "    It does not apply when the entire string is written in capital letters.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    txt : string\n",
    "        A word string which you want to strip off of any punctuations.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    The same txt string with punctuations removed.\n",
    "    \"\"\"\n",
    "\n",
    "    list_clean = []\n",
    "\n",
    "    for toot in toot_list:\n",
    "\n",
    "        temp_list = []\n",
    "        for word in toot:\n",
    "\n",
    "            if word[0] != \"#\": #ignore hashtags from this\n",
    "                if word.isupper():\n",
    "                    temp_list.append(word)  # Add abbreviations etc. as they are\n",
    "                else:\n",
    "                    temp_list.extend(re.sub(r\"([A-Z])\", r\" \\1\", word).split())\n",
    "\n",
    "            else:\n",
    "                temp_list.append(word)\n",
    "\n",
    "        list_clean.append(temp_list)\n",
    "\n",
    "    return list_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fd4b8e0-bbdc-4832-8e36-dd0252ca2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_toot_clean = clean_missing_spaces(words_in_toots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57619a8-1bdd-4027-b414-65006f430ee1",
   "metadata": {},
   "source": [
    "**Removing punctuation**\n",
    "\n",
    "Removing the punctuation to better the result. You can do it before, for instance when removing urls. BUT: If someone mentions a website without hyperlink/ complete urls (which are already gone) like \"pctipp.ch\", the info that it is a website will kind of dissapear. So, I am doing it here, where I can restrict to only look at the last index/element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f366c86c-9905-4007-b86c-43c191528d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_at_end(toot_list):\n",
    "    \"\"\"Replace punctuation found at the end of a string with nothing.\n",
    "    It will remove the punctuation. Uses regex for finding punctuations.\n",
    "    It will drop empty strings, which might appear if the string held only a punctuation.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    txt : string\n",
    "        A word string which you want to strip off of any punctuations.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    The same txt string with punctuations removed.\n",
    "    \"\"\"\n",
    "\n",
    "    list_clean = []\n",
    "    for toot in toot_list:\n",
    "        temp_list = []\n",
    "        for word in toot:\n",
    "    \n",
    "            punctuation = re.compile(r'[^\\w\\s]$')\n",
    "            no_punctuation = punctuation.sub(r'', word)\n",
    "\n",
    "            # Only append non-empty strings to the result list\n",
    "            if no_punctuation.strip():  # Strip to remove any potential leftover spaces\n",
    "                temp_list.append(no_punctuation)\n",
    "\n",
    "        list_clean.append(temp_list)\n",
    "\n",
    "    return list_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "703d9176-5606-4c7d-bb63-4d3486555cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_toot_punct = remove_punctuation_at_end(words_in_toot_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90716353-7695-493d-b321-7348b4263d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_in_toot_punct[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40d8ab-303f-44af-a9dc-b38ecdf7e613",
   "metadata": {},
   "source": [
    "**Converting all strings into all lower characters**\n",
    "\n",
    "Now, I can convert all the words of a toot such that they only consist of all small letters, which is need for later techniques like frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "757edeb0-df09-410e-9214-58fbab587489",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_toot_all_clean = [[word.lower() for word in toot] for toot in words_in_toot_punct]\n",
    "#words_in_toot_all_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baf2f8-7b0c-4a7d-9511-9f55b8520374",
   "metadata": {},
   "source": [
    "**Dropping stopwords**\n",
    "\n",
    "Words that do not add meaningful information to the text are referred to as “stop words” and include commonly appearing words such as who, what, you. The obviously depend on the language (which is why I focused on solely German posts), you download and specify the language using the NLTK package, which comes with lists of stopwords - depending on the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13b4ffa3-754e-4628-9c5b-ca01b2a8b1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/steffi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d50a616-924d-4deb-910c-1ee3ae14b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toots_no_sw = [[word for word in toot_words if not word in stop_words]\n",
    "              for toot_words in words_in_toot_all_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d02f82a7-5257-4718-b1a8-dbf2f4a842dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toots_no_sw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a977bf-883b-4641-9820-bb7a0ba2f64f",
   "metadata": {},
   "source": [
    "**Removing the so called collection words**\n",
    "\n",
    "It is common to remove the so called collection words: collection words are the words that you used to collect your posts from Mastodon - so your hashtag of choice and similar writings as well. In my case that would be #migros but also migros, because I already know that every post contains that word. And that might skew the word frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa1be396-20af-4e5b-995b-ed817ca61692",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_words = [\"#migros\", \"migros\"]\n",
    "\n",
    "toots_no_cw = [[word for word in toot_words if not word in collection_words]\n",
    "               for toot_words in toots_no_sw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b2ec7-9d37-4402-83fc-de9a60cde804",
   "metadata": {},
   "source": [
    "**Count words - frequencies**\n",
    "\n",
    "To get the count of how many times each word appears in the sample, one can use the built-in Python library collections. The collections.Counter object has a useful method most_common that will return the most commonly used words and the number of times that they are used. As a first step, I am going to flatten my list of lists (using itertools) - for the following step it is okay to have all the words in one simple list. After that I print the 25 most common words from the scraped posts. Also, using len() to see how many unique words there are in the posts.\n",
    "\n",
    "I am going to store the result in a Dataframe and make a bar plot. Even though the Migros hashtag was not very informative, the technique is the same for any other hashtag and the code/ functions can be used accordingly for all hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68bf4918-d27a-4258-972c-079869ec94a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#news', 50),\n",
       " ('jahr', 17),\n",
       " ('mehr', 17),\n",
       " ('verkauft', 17),\n",
       " ('#schweiz', 16),\n",
       " ('#coop', 14),\n",
       " ('franken', 14),\n",
       " ('schweizer', 13),\n",
       " ('filialen', 12),\n",
       " ('neue', 12),\n",
       " ('dienstag', 11),\n",
       " ('gefunden', 11),\n",
       " ('mal', 11),\n",
       " ('bank', 10),\n",
       " ('unternehmen', 10),\n",
       " ('schweiz', 10),\n",
       " ('heute', 10),\n",
       " ('übernimmt', 9),\n",
       " ('läden', 9),\n",
       " ('beim', 9),\n",
       " ('sport', 9),\n",
       " ('tochter', 8),\n",
       " ('gibt', 8),\n",
       " ('laut', 8),\n",
       " ('schon', 8)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = list(itertools.chain(*toots_no_cw))\n",
    "\n",
    "counts_words = collections.Counter(all_words)\n",
    "\n",
    "counts_words.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33fbe161-ccb8-4c7f-a03e-c9dc0f5586f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2067"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "431e41b8-c98e-467d-8c08-1271e47d262f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#news</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jahr</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mehr</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>verkauft</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#schweiz</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words  count\n",
       "0     #news     50\n",
       "1      jahr     17\n",
       "2      mehr     17\n",
       "3  verkauft     17\n",
       "4  #schweiz     16"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_25 = pd.DataFrame(counts_words.most_common(15),\n",
    "                             columns=['words', 'count'])\n",
    "\n",
    "most_common_25.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
